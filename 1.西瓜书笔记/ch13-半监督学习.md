# 第十三章 半监督学习

1. **主动学习（Active Learning）**
  - 主动学习（Active Learning）是一种机器学习的方法，旨在提高训练模型的效率和准确性。在传统的机器学习中，通常需要大量的标记数据来训练模型，然后使用该模型进行预测。但是，标记数据的收集和准备往往是耗时和昂贵的。**主动学习的目标是通过选择最有价值的样本来减少标记数据的需求。**
  - 主动学习的**基本思想是，在训练模型的过程中，不仅仅是被动地使用已有的标记数据，而是主动地选择一些未标记的样本**，然后请人类专家或模型本身来标记这些样本。**选择哪些样本进行标记的过程是主动学习的关键。**
  - **主动学习通常使用一种叫做"不确定性采样"（Uncertainty Sampling）的方法来选择要标记的样本**。这种方法**会在模型对未标记样本进行预测时，关注那些模型预测结果最为不确定的样本**。例如，在二分类问题中，一个样本可能距离分类决策边界很近，模型很难确定其分类，那么这个样本就是一个不确定的样本，可以选择标记它来改善模型的预测能力。
  - 另一种常用的主动学习方法是**基于模型不确定性的抽样方法**，例如使用不确定性估计（Uncertainty Estimation）的方法，如基于不确定性的置信度或熵等指标来选择样本。**这些方法通常利用模型在样本空间的不确定性来衡量样本的价值，以便在训练过程中选择最具信息量的样本。**
  - **通过选择最有价值的样本进行标记，主动学习可以在相对较少的标记数据的情况下构建高性能的模型**。这对于训练数据有限或者标记数据成本较高的任务尤为重要。通过主动学习，可以最大程度地利用有限的标记数据，从而提高模型的泛化能力和预测性能。

2. 事实上，**没有专家干涉，也可利用无标记样本数据的信息。**
若能观察到图中的未标记样本，则将很有把握地判别为正例。
![20230613213915](https://cdn.jsdelivr.net/gh/Corner430/Picture1/images/20230613213915.png)

3. **让学习器不依赖外界交互，自动地利用未标记样本来提升学习性能，就是半监督学习（semi-supervised learning）**

4. **要利用未标记样本，必然要做一些将未标记样本所揭示的数据分布信息与类别标记相联系的假设。**
   1. 聚类假设（cluster assumption）
   2. 流形假设（manifold assumption）
> 事实上，无论聚类假设还是流形假设，其本质都是“相似的样本拥有相似的输出”这个基本假设

5. **半监督学习可进一步划分为纯（pure）半监督学习和直推学习（transductive learning），前者假定训练数据中的未标记样本并非待预测的数据，而后者则假定学习过程中所考虑的未标记样本恰是待预测数据，学习的目的就是在这些未标记样本上获得最优泛化性能。**
一图胜千言：
![20230613214852](https://cdn.jsdelivr.net/gh/Corner430/Picture1/images/20230613214852.png)

6. 生成式方法（Generative Methods）
- 生成式方法（Generative Methods）是直接基于生成式模型的方法。**此类方法假设所有数据（无论是否有标记）都是由同一个潜在的模型“生成”的。**这个假设使得我们能通过潜在模型的参数将未标记数据与学习目标联系起来，而未标记数据的标记则可看作模型的确实参数。

- **此类方法的区别主要在于生成式模型的假设，不同的模型假设将产生不同的方法。**

- 遗憾的是，**在现实任务中往往很难事先做出准确的模型假设，除非拥有充分可靠的领域知识。**

- 生成式方法常用的模型包括：
  1. 高斯混合模型（Gaussian Mixture Model，GMM）：GMM 是一种**概率模型，假设数据由多个高斯分布组合而成**。通过学习高斯分布的参数，GMM 可以生成新的数据样本。
  2. 隐马尔可夫模型（Hidden Markov Model，HMM）：HMM 是一种**时序模型，用于建模具有隐含状态的序列数据**。HMM 假设数据的生成过程是一个马尔可夫过程，通过学习转移矩阵和观测概率，HMM 可以生成与原始序列类似的新序列。
  3. 生成对抗网络（Generative Adversarial Network，GAN）：**GAN 是一种基于博弈论的生成模型，由生成器（Generator）和判别器（Discriminator）组成**。生成器试图生成逼真的数据样本，而判别器则试图区分生成的样本和真实样本。通过对抗训练，生成器逐渐学习生成高质量的数据样本。
  4. 变分自编码器（Variational Autoencoder，VAE）：**VAE 是一种基于神经网络的生成模型，通过学习数据样本的潜在变量分布，实现数据的生成和重构**。VAE 通过编码器将数据映射到潜在空间，再通过解码器将潜在变量映射回数据空间，从而生成新的数据样本。

7. 半监督支持向量机(Semi-Supervised Support Vector Machine, 简称S3VM)是支持向量机在半监督学习上的推广。**在不考虑未标记样本时，支持向量机试图找到最大间隔划分超平面，而在考虑未标记样本后，S3VM试图找到能将两类有标记样本分开，且穿过数据低密度区域的划分超平面**.

8. 半监督SVM的**基本思想是，通过在支持向量机的优化目标函数中引入无标签数据的约束，利用无标签数据的分布信息来提供额外的学习信号**。这样，模型可以通过利用无标签数据的分布特征来更好地学习分类边界，从而提高分类器的性能。
半监督SVM的训练过程包括以下步骤：
  1. 初始训练：使用有标签数据训练一个标准的支持向量机分类器。
  2. 标签传播：**使用该分类器对无标签数据进行预测，将预测结果作为无标签数据的伪标签。**
  3. 重新训练：将有标签数据和带有伪标签的无标签数据合并，重新训练支持向量机分类器。
  4. 重复迭代：重复执行步骤2和步骤3，直到达到一定的迭代次数或收敛条件。
通过不断迭代的过程，半监督SVM可以逐渐利用无标签数据的信息进行学习，从而提高分类器的泛化能力。

半监督SVM的优点在于可以利用未标记数据来提供额外的信息，从而扩大训练数据集，改善模型性能。它尤其适用于标记数据稀缺或者标记过程代价较高的情况。然而，**半监督SVM也面临一些挑战，如如何准确传播标签、无标签数据中的噪声以及类别不平衡等问题**。因此，在使用半监督SVM时需要谨慎处理这些问题，以获得更好的结果。

9. 图半监督学习（Graph Semi-Supervised Learning）
- **给定一个数据集，我们可将其映射为一个图，数据集中每个样本对应于图中一个结点，若两个样本之间的相似度很高(或相关性很强)，则对应的结点之间存在一条边, 边的“强度”(strength)正比于样本之间的相似度(或相关性)**。我们可将有标记样本所对应的结点想象为染过色，而未标记样本所对应的结点尚未染色。于是，半监督学习就对应于“颜色”在图上扩散或传播的过程。**由于一个图对应了一个矩阵，这就使得我们能基于矩阵运算来进行半监督学习算法的推导与分析.**

- 图半监督学习（Graph Semi-Supervised Learning）是一种机器学习方法，旨在利用图结构数据中的标记和未标记节点信息来进行分类或回归任务。**与传统的半监督学习方法相比，图半监督学习更适用于处理具有图结构的数据，例如社交网络、推荐系统、生物网络等。**

- 图半监督学习的**基本思想是将节点之间的连接关系转化为图结构，利用图中节点的拓扑结构和特征信息来推断未标记节点的标签**。以下是图半监督学习的关键要素和步骤：
  1. 图构建：将数据集中的节点和它们之间的连接关系表示为图结构。连接关系可以是节点之间的边、邻接矩阵或者相似性矩阵。
  2. 节点特征提取：为每个节点提取特征表示，这些特征可以是节点的属性、结构信息或其他相关信息。常用的特征提取方法包括节点属性传播、图卷积网络（Graph Convolutional Networks）等。
  3. 标记传播：**利用已标记节点的标签信息，通过图结构进行标签传播，将已标记节点的标签信息传递给未标记节点**。传播的方式可以是基于图的扩散算法，如拉普拉斯传播（Laplacian Propagation）或基于图卷积网络的方法。
  4. 学习模型：基于已标记和未标记节点的特征和标签信息，训练一个分类器或回归模型来进行预测。常用的模型包括支持向量机、随机森林、神经网络等。

- 图半监督学习的优点在于它能够利用图结构中的节点连接关系和特征信息来推断未标记节点的标签，从而提供更准确的预测结果。它对于处理具有图结构的数据和标记数据不充分的情况下特别有用。然而，**图半监督学习也面临一些挑战，如图噪声、图稀疏性、标签传播的准确性等问题。**

- 图半监督学习方法在概念上相当清晰，且易于通过对涉矩阵运算的分析来探索算法性质。但此类算法的缺陷也相当明显：
  - 存储开销
  - 由于构图过程中仅能考虑训练样本集，**难以判知新样本在图中的位置。**

10. 基于分歧的方法（Divergence-Based Methods）
与生成式方法、半监督SVM、图半监督学习等基于单学习器利用未标记数据不同，**基于分歧的方法（Divergence-Based Methods）使用多学习器，而学习器之间的“分歧”（disagreement）对未标记数据的利用至关重要**

11. 聚类是一种典型的无监督学习任务，然而在现实聚类任务中我们往往能获得一些额外的监督信息。于是可通过**半监督聚类（Semi-Supervised Clustering）**来利用监督信息以获得更好的聚类效果。

12. 聚类任务中获得的监督信息大致有两种，**第一种类型是“必连”（must-link）与“勿连”（cannot-link）约束，前者是指样本必属于同一个簇，后者是指样本必不属于同一个簇**

13. 阅读材料
![20230613225704](https://cdn.jsdelivr.net/gh/Corner430/Picture1/images/20230613225704.png)
> 许多集成学习研究者认为：只要能使用多个学习器即可将弱学习器性能提升到极高，无须使用未标记样本；许多半监督学习研究者认为：只要能使用未标记样本即可将弱学习器性能提升到极高，无须使用多学习器。但这两种看法都有其局限.

14. 半监督学习**不仅仅可应用于半监督分类和聚类，也可用于半监督回归、降维等方面**

15. **确保半监督学习的泛化性能至少不差于仅利用有标记样本仍是一个未解决的问题**
