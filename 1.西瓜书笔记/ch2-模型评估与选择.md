# 第二章 模型评估与选择

1. **欠拟合不是问题，过拟合无法避免，只能缓解**。
2. 测试集和训练集**应该尽可能的互斥**，即测试样本尽量不在训练集中出现、未在训练过程中使用过。**考试题和练习题一样，还有什么意义？**
3. 训练->验证->测试
4. 查准率、查全率、F1
5. ROC、AUC
6. 代价敏感错误率与代价曲线（就是第一类错误）
7. 偏差与方差

------------------------------------

## 特征工程相关

### 留出法（hold-out）

1. “留出法”（hold-out）直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为测试集T，即$D = S \cup T$,$S \cap T = \emptyset$。在S上训练出模型后，用T来评估其测试误差，作为对泛化误差的估计。
2. 需要注意的是，训练/测试集的划分要尽可能保持**数据分布的一致性**，避免因数据划分过程中引入额外的偏差而对最终结果产生影响。
3. 单次使用留出法得到的估计结果往往不够稳定可靠，在使用留出法时，**一般要采用若干次随即划分、重复进行实验评估后取平均值**作为留出法的评估结果。 
4. 这里有一个很严重的问题，如果**训练集占总样本的数量比例过大**，将会导致训练出的模型过于接近直接用全样本训练的模型，从而降低了评估结果的保真性。故而常见做法是将大约**2/3 ~ 4/5**的样本用于训练，剩余样本用于测试。一般而言，**测试集至少应包含30个样例**。

### 交叉验证法（cross validation）
![20230521233538](https://cdn.jsdelivr.net/gh/Corner430/Picture/images/20230521233538.png)
1. 如果将m个样本分成了m份，那就是**留一法（Leave-One-Out，简称LOO）**。留一法的评估结果往往被认为比较准确，但这是未必的。

### 自助法（bootstrapping）
1. **在留出法和交叉验证法中有一个缺陷**，就是由于保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比D小，这必然会引入一些因训练样本规模不同而导致的估计偏差。留一法的计算复杂度又太高。
![20230521234305](https://cdn.jsdelivr.net/gh/Corner430/Picture/images/20230521234305.png)
2. 自助法在数据集较小、难以有效划分训练/测试集时很有用
3. 自助法能从初始数据集中产生多个不同的训练集，这对**集成学习**等方法有很大的好处。
4. 自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。
5. **在初始数据量足够时，留出法和交叉验证法更常用一些**
