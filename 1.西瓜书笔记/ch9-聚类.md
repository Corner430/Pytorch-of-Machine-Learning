# 第九章 聚类

1. 无监督学习（unsupervised learning）：聚类（clustering）、密度估计（density estimation）、异常检测（anomaly-detection）
2. 聚类既能作为一个单独过程，用于找寻数据内在的分布结构，也可作为分类等其他学习任务的前驱过程。

----------------------------------------------------
## 9.1 聚类性能度量亦称聚类“有效性指标”（validity index）
1. 若明确了最终将要使用的性能度量，**则可直接将其作为聚类过程的优化目标**，从而更好地得到符合要求的聚类结果
2. 聚类结果的“簇内相似度”（intra-cluster similarity）高且“簇间相似度”（inter-cluster similarity）低.
3. 聚类性能度量大致有两类。
   1. 外部指标（external index）：将聚类结果与某个“参考模型”（reference model）进行比较
   2. 内部指标（internal index）：直接考察聚类结果而不利用任何参考模型

-------------------------------------------------------
## 9.2 距离计算
![20230612231236](https://cdn.jsdelivr.net/gh/Corner430/Picture1/images/20230612231236.png)
![20230612231248](https://cdn.jsdelivr.net/gh/Corner430/Picture1/images/20230612231248.png)

1. “闵可夫斯基距离”(Minkowski distance)
2. VDM (Value Diference Metric)

> 我们常将属性划分为“连续属性”(continuousattribute)和“离散属性”(categorical attribute)，前者在定义域上有无穷多个可能的取值，后者在定义域上是有限个取值。然而，在讨论距离计算时，属性上是否定义了“序”关系更为重要。
> 闵可夫斯基距离可用于有序属性，对无序属性可采用VDM

3. 将闵可夫斯基距离和VDM结合即可处理**混合属性**
4. 当样本空间不同属性的重要性不同时，可使用**“加权距离”（weighted distance）**
5. 用于相似度度量的距离未必一定药满足距离度量的所有基本性质，尤其是直递性
![20230612231416](https://cdn.jsdelivr.net/gh/Corner430/Picture1/images/20230612231416.png)

-----------------------------------------------------------------------------------------
3. 聚类的种类
- 原型聚类：亦称为“基于原型的聚类”（prototype-based clustering），此类算法假设聚类结构能通过一组原型刻画，**在现实聚类任务中极为常用**。
  - k均值算法
  - 学习向量量化
  - 高斯混合聚类
- 密度聚类：密度聚类亦称“基于密度的聚类”(density-based clustering)，此类算法**假设聚类结构能通过样本分布的紧密程度确定**。通常情形下，密度聚类算法从样本密度的角度来考察样本之间的可连接性，并基于可连接样本不断扩展聚类簇以获得最终的聚类结果.
- 层次聚类：层次聚类(hierarchical clustering)试图在不同层次对数据集进行划分，从而形成树形的聚类结构。数据集的划分可采用“自底向上”的聚合策略，也可采用“自顶向下”的分拆策略.

4. 聚类也可以集成。