{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义逻辑回归模型类\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        # 定义线性层，输入维度为 input_dim，输出维度为 1\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 使用 sigmoid 函数将线性输出转换为概率值\n",
    "        return torch.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    # 初始化权重\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.constant_(m.bias, val=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_X, train_y, test_X, test_y, num_epochs, lr, weight_decay):\n",
    "    # 训练函数，用于训练神经网络模型并计算损失\n",
    "    # 如果提供了测试数据，则返回训练集损失和测试集损失，否则返回训练集损失\n",
    "\n",
    "    # 创建 SGD 优化器，用于参数更新\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # 在每个训练周期内进行训练和评估\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()  # 清零梯度\n",
    "        l = loss(net(train_X), train_y)  # 计算损失\n",
    "        l.backward()  # 反向传播计算梯度\n",
    "        optimizer.step()  # 更新模型参数\n",
    "        # print('epoch %d, loss: %f' % (epoch + 1, l.item()))\n",
    "\n",
    "    # 计算并记录训练集的误差\n",
    "    train_loss = loss(net(train_X), train_y)\n",
    "\n",
    "    # 如果提供了测试集标签，则计算并记录测试集的误差\n",
    "    if test_y is not None:\n",
    "        test_loss = loss(net(test_X), test_y)\n",
    "\n",
    "        return train_loss, test_loss\n",
    "    \n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    # 使用 pandas 读取数据并处理数据，返回特征张量和标签张量。\n",
    "\n",
    "    data_path = r\"watermelon3_0_Ch.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    # 在每个样本中，第一个特征是 编号，我们将其从数据集中删除\n",
    "    all_features = data.iloc[:, 1:-1]\n",
    "\n",
    "    # 处理离散值，用one-hot编码\n",
    "    all_features = pd.get_dummies(all_features, dummy_na=True)\n",
    "\n",
    "    features = torch.tensor(all_features.values, dtype=torch.float32)\n",
    "    # 将标签列的 \"是\" 转换为 1，\"否\" 转换为 0\n",
    "    labels = data[\"好瓜\"].apply(lambda x: 1 if x == \"是\" else 0)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32).reshape(-1, 1)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_fold_data(k, i, X, y):\n",
    "    \"\"\"获取第 i 折交叉验证时所需要的训练和验证数据\n",
    "\n",
    "    Args:\n",
    "        k (int): 折数\n",
    "        i (int): 当前折索引\n",
    "        X (torch.Tensor): 特征数据\n",
    "        y (torch.Tensor): 标签数据\n",
    "\n",
    "    Returns:\n",
    "        X_train (torch.Tensor): 训练集特征数据\n",
    "        y_train (torch.Tensor): 训练集标签数据\n",
    "        X_valid (torch.Tensor): 验证集特征数据\n",
    "        y_valid (torch.Tensor): 验证集标签数据\n",
    "    \"\"\"\n",
    "    assert k > 1  # 确保折数大于 1\n",
    "\n",
    "    fold_size = X.shape[0] // k  # 每折的样本数\n",
    "    X_train, y_train = None, None  # 初始化训练集\n",
    "\n",
    "    # 迭代每一折，获取训练集和验证集\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)  # 当前折的索引范围\n",
    "        X_part, y_part = X[idx, :], y[idx]  # 当前折的数据\n",
    "\n",
    "        if j == i:  # 当前折为验证集\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:  # 训练集的第一个折\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:  # 训练集的其他折\n",
    "            X_train = torch.cat((X_train, X_part), dim=0)\n",
    "            y_train = torch.cat((y_train, y_part), dim=0)\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(k, features, labels, num_epochs, learning_rate, weight_decay):\n",
    "    # 执行 k 折交叉验证来评估神经网络模型的性能\n",
    "    train_l_sum, valid_l_sum = 0, 0  # 初始化训练集和验证集的损失和\n",
    "\n",
    "    # 循环每一折\n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k, i, features, labels)  # 获取当前折的训练集和验证集\n",
    "        net = LogisticRegressionModel(features.shape[1])  # 重新创建逻辑回归模型\n",
    "        # net.apply(weight_init)  # 初始化模型参数\n",
    "        train_loss, valid_loss = train(net, *data, num_epochs, learning_rate, weight_decay)  # 训练并返回损失\n",
    "\n",
    "        train_l_sum += train_loss  # 训练集损失\n",
    "        valid_l_sum += valid_loss # 验证集损失\n",
    "        \n",
    "        print('fold %d, train loss %f, valid loss %f' % (i, train_loss, valid_loss))  # 打印每一折的损失\n",
    "    \n",
    "    average_train_l = train_l_sum / k  # 训练集损失均值\n",
    "    average_valid_l = valid_l_sum / k  # 验证集损失均值\n",
    "\n",
    "    return average_train_l, average_valid_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0, train loss 0.442799, valid loss 0.375743\n",
      "fold 1, train loss 0.433537, valid loss 0.441877\n",
      "fold 2, train loss 0.452867, valid loss 0.251866\n",
      "fold 3, train loss 0.414862, valid loss 0.516991\n",
      "fold 4, train loss 0.430695, valid loss 0.448435\n",
      "fold 5, train loss 0.402970, valid loss 0.905296\n",
      "fold 6, train loss 0.338243, valid loss 1.644442\n",
      "fold 7, train loss 0.414794, valid loss 0.550190\n",
      "fold 8, train loss 0.430925, valid loss 0.572379\n",
      "fold 9, train loss 0.420944, valid loss 0.706803\n",
      "fold 10, train loss 0.449080, valid loss 0.213288\n",
      "fold 11, train loss 0.429521, valid loss 0.521070\n",
      "fold 12, train loss 0.402463, valid loss 0.924816\n",
      "fold 13, train loss 0.425622, valid loss 0.413816\n",
      "fold 14, train loss 0.345469, valid loss 1.728418\n",
      "fold 15, train loss 0.429824, valid loss 0.459408\n",
      "fold 16, train loss 0.413915, valid loss 0.712980\n",
      "训练集平均损失：0.416384\n",
      "验证集平均损失：0.669872\n"
     ]
    }
   ],
   "source": [
    "features, labels = get_data()\n",
    "loss = nn.BCELoss()  # 二元交叉熵损失函数\n",
    "num_epochs, lr, weight_decay = 100, 0.07, 1e-2  # 训练周期数、学习率、权重衰减系数\n",
    "\n",
    "avg_train_loss, avg_valid_loss = k_fold(17,features, labels, num_epochs, lr, weight_decay)\n",
    "print(f\"训练集平均损失：{avg_train_loss:.6f}\")\n",
    "print(f\"验证集平均损失：{avg_valid_loss:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
